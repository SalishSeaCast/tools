{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from salishsea_tools import rivertools, nc_tools, viz_tools\n",
    "from salishsea_tools import river_202101 as rivers\n",
    "\n",
    "prop_dict_name ='river_202101'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what coordinates are you using?\n",
    "gridcoords = 'coordinates_seagrid_SalishSea201702.nc'\n",
    "coords_file = '../../../grid/'+gridcoords\n",
    "# where is the river information? \n",
    "prop_dict = rivers.prop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dimensions for netcdf files\n",
    "fB = xr.open_dataset(coords_file, decode_times=False)\n",
    "lat = fB['nav_lat'][:]\n",
    "lon = fB['nav_lon'][:]\n",
    "e1t = fB['e1t'][0,:]\n",
    "e2t = fB['e2t'][0,:]\n",
    "horz_area = e1t*e2t\n",
    "fB.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of watersheds we are including\n",
    "names = ['bute', 'evi_n', 'jervis', 'evi_s', 'howe', 'jdf', 'skagit', 'puget', 'toba', 'fraser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01T00:00:00+00:00 2019-12-31T00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Constant and data ranges etc\n",
    "year = 2019\n",
    "smonth = 1\n",
    "emonth = 12\n",
    "startdate = arrow.get(year, smonth, 1)\n",
    "enddate = arrow.get(year, emonth, 31)\n",
    "print (startdate, enddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_river(river_name, ps):\n",
    "    river_flow = pd.read_csv(f'river_flows/{river_name}_flow', header=None, sep='\\s+', index_col=False,\n",
    "                      names=['year', 'month', 'day', 'flow'])\n",
    "    river_flow['date'] = pd.to_datetime(river_flow.drop(columns='flow'))\n",
    "    river_flow.set_index('date', inplace=True)\n",
    "    river_flow = river_flow.drop(columns=['year', 'month', 'day'])\n",
    "    if ps == 'primary':\n",
    "        river_flow = river_flow.rename(columns={'flow': 'Primary River Flow'})\n",
    "    elif ps == 'secondary':\n",
    "        river_flow = river_flow.rename(columns={'flow': 'Secondary River Flow'})\n",
    "    return river_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_river_Theodosia():\n",
    "    part1 = pd.read_csv('river_flows/Theodosia_Scotty_flow', header=None, sep='\\s+', index_col=False,\n",
    "                      names=['year', 'month', 'day', 'flow'])\n",
    "    part2 = pd.read_csv('river_flows/Theodosia_Bypass_flow', header=None, sep='\\s+', index_col=False,\n",
    "                      names=['year', 'month', 'day', 'flow'])\n",
    "    part3 = pd.read_csv('river_flows/Theodosia_Diversion_flow', header=None, sep='\\s+', index_col=False,\n",
    "                      names=['year', 'month', 'day', 'flow'])\n",
    "    for part in [part1, part2, part3]:\n",
    "        part['date'] = pd.to_datetime(part.drop(columns='flow'))\n",
    "        part.set_index('date', inplace=True)\n",
    "        part.drop(columns=['year', 'month', 'day'], inplace=True)\n",
    "    part1 = part1.rename(columns={'flow': 'Scotty'})\n",
    "    part2 = part2.rename(columns={'flow': 'Bypass'})\n",
    "    part3 = part3.rename(columns={'flow': 'Diversion'})\n",
    "    theodosia = (part1.merge(part2, how='inner', on='date')).merge(part3, how='inner', on='date')\n",
    "    theodosia['Secondary River Flow'] = theodosia['Scotty'] + theodosia['Diversion'] - theodosia['Bypass']\n",
    "    return theodosia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_a_pair(water_shed, watershed_from_river, startdate, enddate,\n",
    "              primary_river_name, use_secondary, \n",
    "              secondary_river_name='Null', subtract_primary=False):\n",
    "    primary_river = read_river(primary_river_name, 'primary')\n",
    "    print (primary_river_name, 'into gaps')\n",
    "    good, fillit = check_for_gaps(primary_river_name, primary_river['Primary River Flow'], startdate, enddate)\n",
    "    if not good:\n",
    "        print ('filling', primary_river_name)\n",
    "        myfill = fillit[fillit.index > np.datetime64(dt.datetime(2006, 12, 31))]\n",
    "        fillitd = pd.DataFrame(index = myfill.index, data = {'Primary River Flow': myfill})\n",
    "        primary_river = primary_river.append(fillitd)\n",
    "        primary_river = primary_river.sort_index()\n",
    "            \n",
    "    if use_secondary:\n",
    "        print(secondary_river_name, 'read and check')\n",
    "        if secondary_river_name == \"Theodosia\":\n",
    "            secondary_river = read_river_Theodosia()\n",
    "            \n",
    "        else:\n",
    "            secondary_river = read_river(secondary_river_name, 'secondary')\n",
    "        good, fillit = check_for_gaps(secondary_river_name, secondary_river['Secondary River Flow'], \n",
    "                                      startdate, enddate)\n",
    "        if not good:\n",
    "            print ('filling', secondary_river_name)\n",
    "            myfill = fillit[fillit.index > np.datetime64(dt.datetime(2006, 12, 31))]\n",
    "            fillitd = pd.DataFrame(index = myfill.index, data = {'Secondary River Flow': myfill})\n",
    "            secondary_river = secondary_river.append(fillitd)\n",
    "            secondary_river = secondary_river.sort_index()\n",
    "            secondary_river.index.name = 'date'\n",
    "                        \n",
    "        rivers = primary_river.merge(secondary_river, how='inner', on='date')\n",
    "        rivers['Daily Flow'] = (rivers['Primary River Flow'] * \n",
    "                        watershed_from_river[water_shed]['primary']\n",
    "                        + rivers['Secondary River Flow'] \n",
    "                        * watershed_from_river[water_shed]['secondary'])\n",
    "    else:\n",
    "        rivers = primary_river\n",
    "        rivers['Daily Flow'] = (primary_river['Primary River Flow'] * \n",
    "                                watershed_from_river[water_shed]['primary'])\n",
    "\n",
    "    \n",
    "    return rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fraser(watershed_from_river, startdate, enddate,\n",
    "              primary_river_name, secondary_river_name):\n",
    "    primary_river = read_river(primary_river_name, 'primary')\n",
    "    good, fillit = check_for_gaps(primary_river_name, primary_river['Primary River Flow'], startdate, enddate)\n",
    "    if not good:\n",
    "        print ('filling', primary_river_name)\n",
    "        myfill = fillit[fillit.index > np.datetime64(dt.datetime(2006, 12, 31))]\n",
    "        fillitd = pd.DataFrame(index = myfill.index, data = {'Primary River Flow': myfill})\n",
    "        primary_river = primary_river.append(fillitd)\n",
    "        primary_river = primary_river.sort_index()\n",
    "            \n",
    "    secondary_river = read_river(secondary_river_name, 'secondary')\n",
    "    good, fillit = check_for_gaps(secondary_river_name, secondary_river['Secondary River Flow'], \n",
    "                                      startdate, enddate)\n",
    "    if not good:\n",
    "        print ('filling', secondary_river_name)\n",
    "        myfill = fillit[fillit.index > np.datetime64(dt.datetime(2006, 12, 31))]\n",
    "        fillitd = pd.DataFrame(index = myfill.index, data = {'Secondary River Flow': myfill})\n",
    "        secondary_river = secondary_river.append(fillitd)\n",
    "        secondary_river = secondary_river.sort_index()    \n",
    "                        \n",
    "    Fraser = primary_river.merge(secondary_river, how='inner', on='date')\n",
    "    Fraser['Daily Flow'] = (Fraser['Primary River Flow'] * \n",
    "                        watershed_from_river['fraser']['primary']\n",
    "                        + Fraser['Secondary River Flow'] \n",
    "                        * watershed_from_river['fraser']['secondary'] *\n",
    "                           watershed_from_river['fraser']['nico_into_fraser'])\n",
    "    secondary_river['Daily Flow'] = (secondary_river['Secondary River Flow'] *\n",
    "                                      watershed_from_river['fraser']['secondary'] *\n",
    "                           (1 - watershed_from_river['fraser']['nico_into_fraser']))\n",
    "\n",
    "    \n",
    "    return Fraser, secondary_river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_gaps(name, flows, startdate, enddate):\n",
    "    subset = flows[(flows.index <= enddate.naive) & (flows.index >= startdate.naive)]\n",
    "    print (name, len(subset.index), 'index count')\n",
    "    diffy = subset.index[1:] - subset.index[:-1]\n",
    "    day = dt.datetime(2020, 1, 2) - dt.datetime(2020, 1, 1)\n",
    "    gaps = subset[1:][diffy > day]\n",
    "    gap_length = diffy[diffy > day]\n",
    "    if len(gap_length) == 0:\n",
    "        good = True\n",
    "        fillit = pd.Series(dtype='float64')\n",
    "    else:\n",
    "        good = False\n",
    "        print ('got a gap', name)\n",
    "        fillvalue, filldate = patch_gaps(name, flows, gaps, gap_length, day)\n",
    "        fillit = pd.Series(fillvalue, index=filldate)\n",
    "\n",
    "    return good, fillit    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dictionary = {'Englishman': 'Salmon_Sayward',\n",
    "                      'Theodosia': 'Englishman',\n",
    "                      'Roberts_Roberts': 'Englishman',\n",
    "                      'Salmon_Sayward': 'Englishman',\n",
    "                      'Squamish_Brackendale': 'Homathko_Mouth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_gaps(name, flows, gaps, gap_length, day):\n",
    "    filler = read_river(matching_dictionary[name], 'primary')\n",
    "    fillvalue = np.zeros((len(gaps.index), gap_length.max().days))\n",
    "    filldate = np.zeros((len(gaps.index), gap_length.max().days), dtype='datetime64[ns]')\n",
    "    for ig, gap in enumerate(gaps.index):\n",
    "        summit = 0\n",
    "        sumsq = 0\n",
    "        count = 0\n",
    "        print (gap_length[ig], gap, name)\n",
    "        for deltat in np.arange(-2*gap_length[ig]+day, gap_length[ig], day):\n",
    "            summit = summit + filler[filler.index == gap+deltat]['Primary River Flow'].values\n",
    "            sumsq = sumsq + filler[filler.index == gap+deltat]['Primary River Flow'].values**2\n",
    "            count = count + 1\n",
    "        mean = summit/count\n",
    "        var = sumsq/count - mean**2/count\n",
    "        sumbase = 0\n",
    "        sumfill = 0\n",
    "        sumratio = 0\n",
    "        sumratio2 = 0\n",
    "        count = 0\n",
    "        for deltat in np.arange(-2*gap_length[ig]+day, -gap_length[ig]+day, day):\n",
    "            sumbase = sumbase + flows[flows.index == gap+deltat].values\n",
    "            sumfill = sumfill + filler[filler.index == gap+deltat]['Primary River Flow'].values\n",
    "            ratio = (flows[flows.index == gap+deltat].values /\n",
    "                filler[filler.index == gap+deltat]['Primary River Flow'].values)\n",
    "            sumratio = sumratio + ratio\n",
    "            sumratio2 = sumratio2 + ratio**2\n",
    "            count = count + 1\n",
    "        for deltat in np.arange(0, gap_length[ig], day):\n",
    "            sumbase = sumbase + flows[flows.index == gap+deltat].values\n",
    "            sumfill = sumfill + filler[filler.index == gap+deltat]['Primary River Flow'].values\n",
    "            ratio = (flows[flows.index == gap+deltat].values / \n",
    "                     filler[filler.index == gap+deltat]['Primary River Flow'].values)\n",
    "            sumratio = sumratio + ratio\n",
    "            sumratio2 = sumratio2 + ratio**2\n",
    "            count = count + 1\n",
    "        meanratio = sumratio/count\n",
    "        varratio = sumratio2/count - meanratio**2/count\n",
    "        if np.sqrt(var)/mean < np.sqrt(varratio)/meanratio : \n",
    "            uselinear = True\n",
    "        else:\n",
    "            uselinear = False\n",
    "        print (uselinear, 'uselinear')\n",
    "        for step, deltat in enumerate(np.arange(-gap_length[ig]+day, day, day)):\n",
    "            if uselinear:\n",
    "                slope = (flows[flows.index == gap].values \n",
    "                 - flows[flows.index == gap-gap_length[ig]].values)/gap_length[ig].days\n",
    "                fillvalue[ig, step] = flows[flows.index == gap-gap_length[ig]] + slope * (step+1)\n",
    "            else:\n",
    "                fillvalue[ig, step] = meanratio * filler[filler.index == gap + deltat].values \n",
    "            filldate[ig, step] = gap + deltat\n",
    "    return fillvalue.flatten(), filldate.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_from_river = {\n",
    "    'bute': {'primary': 2.015},\n",
    "    'jervis': {'primary': 8.810, 'secondary': 140.3},\n",
    "    'howe': {'primary': 2.276},\n",
    "    'jdf': {'primary': 8.501},\n",
    "    'evi_n': {'primary': 10.334},\n",
    "    'evi_s': {'primary': 24.60},\n",
    "    'toba': {'primary': 0.4563, 'secondary': 14.58},\n",
    "    'skagit': {'primary': 1.267, 'secondary': 1.236},\n",
    "    'puget': {'primary': 8.790, 'secondary': 29.09},\n",
    "    'fraser' : {'primary': 1.161, 'secondary': 162, 'nico_into_fraser': 0.83565}\n",
    "}\n",
    "rivers_for_watershed = {\n",
    "    'bute': {'primary': 'Homathko_Mouth',\n",
    "            'secondary': 'False'},\n",
    "    'evi_n': {'primary': 'Salmon_Sayward',\n",
    "             'secondary': 'False'},\n",
    "    'jervis': {'primary': 'Clowhom_ClowhomLake',\n",
    "              'secondary': 'Roberts_Roberts'},\n",
    "    'evi_s': {'primary': 'Englishman', \n",
    "             'secondary': 'False'},\n",
    "    'howe': {'primary': 'Squamish_Brackendale',\n",
    "            'secondary': 'False'},\n",
    "    'jdf': {'primary': 'SanJuan_PortRenfrew',\n",
    "           'secondary': 'False'},\n",
    "    'skagit': {'primary': 'Skagit_MountVernon',\n",
    "              'secondary': 'Snohomish_Monroe'},\n",
    "    'puget': {'primary': 'Nisqually_McKenna',\n",
    "             'secondary': 'Greenwater_Greenwater'},\n",
    "    'toba': {'primary': 'Homathko_Mouth',\n",
    "            'secondary': 'Theodosia'},\n",
    "    'fraser': {'primary': 'Fraser_Hope',\n",
    "              'secondary': 'Nicomekl_203'},\n",
    "}\n",
    "\n",
    "fraserratio = rivers.prop_dict['fraser']['Fraser']['prop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(day, runoff):\n",
    "    \"keep it small and simple, runoff only\"\n",
    "    notebook = 'MakeDailyRiverNCfiles.ipynb'\n",
    "    coords = {\n",
    "        'x' : range(398),\n",
    "        'y' : range(898),\n",
    "        'time_counter' : [0],\n",
    "    }\n",
    "    var_attrs = {'units': 'kg m-2 s-1',\n",
    "                      'long_name': 'runoff_flux'}\n",
    "    \n",
    "    year = day.year\n",
    "    month = day.month\n",
    "    day = day.day\n",
    "    # set up filename to follow NEMO conventions\n",
    "    filename = f'ncfiles/R202102Dailies_y{year}m{month:02}d{day:02}.nc'\n",
    "    print (filename)\n",
    "        \n",
    "    netcdf_title = f'Rivers for y{year}m{month:02}d{day:02}'\n",
    "    ds_attrs = {\n",
    "        'acknowledgements':\n",
    "            'Based on river fit',\n",
    "        'creator_email':\n",
    "            'sallen@eoas.ubc.ca',\n",
    "        'creator_name':\n",
    "            'Salish Sea MEOPAR Project Contributors',\n",
    "        'creator_url':\n",
    "            'https://salishsea-meopar-docs.readthedocs.org/',\n",
    "        'institution':\n",
    "            'UBC EOAS',\n",
    "        'institution_fullname': (\n",
    "            'Earth, Ocean & Atmospheric Sciences,'\n",
    "            ' University of British Columbia'\n",
    "        ),\n",
    "        'title': netcdf_title,\n",
    "        'notebook': notebook,\n",
    "        'rivers_base': prop_dict_name,\n",
    "        'summary': f'Daily Runoff',\n",
    "        'history': (\n",
    "            '[{}] File creation.'\n",
    "            .format(dt.datetime.today().strftime('%Y-%m-%d'))\n",
    "        )\n",
    "        }\n",
    "    runoffs = np.empty((1, runoff.shape[0], runoff.shape[1]))\n",
    "    runoffs[0] = runoff\n",
    "\n",
    "    da = xr.DataArray(\n",
    "            data = runoffs,\n",
    "            name='rorunoff',\n",
    "            dims=('time_counter', 'y', 'x'),\n",
    "            coords = coords,\n",
    "            attrs = var_attrs)\n",
    "    \n",
    "\n",
    "    ds = xr.Dataset(\n",
    "            data_vars={\n",
    "            'rorunoff': da},\n",
    "            coords = coords,\n",
    "            attrs = ds_attrs\n",
    "        )\n",
    "    \n",
    "    encoding = {var: {'zlib': True} for var in ds.data_vars}\n",
    "\n",
    "    ds.to_netcdf(filename, unlimited_dims=('time_counter'),\n",
    "            encoding=encoding,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bute\n",
      "no secondary\n",
      "Homathko_Mouth into gaps\n",
      "Homathko_Mouth 365 index count\n",
      "evi_n\n",
      "no secondary\n",
      "Salmon_Sayward into gaps\n",
      "Salmon_Sayward 365 index count\n",
      "jervis\n",
      "Clowhom_ClowhomLake into gaps\n",
      "Clowhom_ClowhomLake 365 index count\n",
      "Roberts_Roberts read and check\n",
      "Roberts_Roberts 365 index count\n",
      "evi_s\n",
      "no secondary\n",
      "Englishman into gaps\n",
      "Englishman 362 index count\n",
      "got a gap Englishman\n",
      "4 days 00:00:00 2019-05-17 00:00:00 Englishman\n",
      "False uselinear\n",
      "filling Englishman\n",
      "howe\n",
      "no secondary\n",
      "Squamish_Brackendale into gaps\n",
      "Squamish_Brackendale 168 index count\n",
      "got a gap Squamish_Brackendale\n",
      "198 days 00:00:00 2019-10-21 00:00:00 Squamish_Brackendale\n",
      "False uselinear\n",
      "filling Squamish_Brackendale\n",
      "jdf\n",
      "no secondary\n",
      "SanJuan_PortRenfrew into gaps\n",
      "SanJuan_PortRenfrew 365 index count\n",
      "skagit\n",
      "Skagit_MountVernon into gaps\n",
      "Skagit_MountVernon 365 index count\n",
      "Snohomish_Monroe read and check\n",
      "Snohomish_Monroe 365 index count\n",
      "puget\n",
      "Nisqually_McKenna into gaps\n",
      "Nisqually_McKenna 365 index count\n",
      "Greenwater_Greenwater read and check\n",
      "Greenwater_Greenwater 365 index count\n",
      "toba\n",
      "Homathko_Mouth into gaps\n",
      "Homathko_Mouth 365 index count\n",
      "Theodosia read and check\n",
      "Theodosia 365 index count\n",
      "fraser\n",
      "Fraser_Hope 365 index count\n",
      "Nicomekl_203 365 index count\n",
      "ncfiles/R202102Dailies_y2019m01d01.nc\n",
      "ncfiles/R202102Dailies_y2019m01d02.nc\n",
      "ncfiles/R202102Dailies_y2019m01d03.nc\n",
      "ncfiles/R202102Dailies_y2019m01d04.nc\n",
      "ncfiles/R202102Dailies_y2019m01d05.nc\n",
      "ncfiles/R202102Dailies_y2019m01d06.nc\n",
      "ncfiles/R202102Dailies_y2019m01d07.nc\n",
      "ncfiles/R202102Dailies_y2019m01d08.nc\n",
      "ncfiles/R202102Dailies_y2019m01d09.nc\n",
      "ncfiles/R202102Dailies_y2019m01d10.nc\n",
      "ncfiles/R202102Dailies_y2019m01d11.nc\n",
      "ncfiles/R202102Dailies_y2019m01d12.nc\n",
      "ncfiles/R202102Dailies_y2019m01d13.nc\n",
      "ncfiles/R202102Dailies_y2019m01d14.nc\n",
      "ncfiles/R202102Dailies_y2019m01d15.nc\n",
      "ncfiles/R202102Dailies_y2019m01d16.nc\n",
      "ncfiles/R202102Dailies_y2019m01d17.nc\n",
      "ncfiles/R202102Dailies_y2019m01d18.nc\n",
      "ncfiles/R202102Dailies_y2019m01d19.nc\n",
      "ncfiles/R202102Dailies_y2019m01d20.nc\n",
      "ncfiles/R202102Dailies_y2019m01d21.nc\n",
      "ncfiles/R202102Dailies_y2019m01d22.nc\n",
      "ncfiles/R202102Dailies_y2019m01d23.nc\n",
      "ncfiles/R202102Dailies_y2019m01d24.nc\n",
      "ncfiles/R202102Dailies_y2019m01d25.nc\n",
      "ncfiles/R202102Dailies_y2019m01d26.nc\n",
      "ncfiles/R202102Dailies_y2019m01d27.nc\n",
      "ncfiles/R202102Dailies_y2019m01d28.nc\n",
      "ncfiles/R202102Dailies_y2019m01d29.nc\n",
      "ncfiles/R202102Dailies_y2019m01d30.nc\n",
      "ncfiles/R202102Dailies_y2019m01d31.nc\n",
      "ncfiles/R202102Dailies_y2019m02d01.nc\n",
      "ncfiles/R202102Dailies_y2019m02d02.nc\n",
      "ncfiles/R202102Dailies_y2019m02d03.nc\n",
      "ncfiles/R202102Dailies_y2019m02d04.nc\n",
      "ncfiles/R202102Dailies_y2019m02d05.nc\n",
      "ncfiles/R202102Dailies_y2019m02d06.nc\n",
      "ncfiles/R202102Dailies_y2019m02d07.nc\n",
      "ncfiles/R202102Dailies_y2019m02d08.nc\n",
      "ncfiles/R202102Dailies_y2019m02d09.nc\n",
      "ncfiles/R202102Dailies_y2019m02d10.nc\n",
      "ncfiles/R202102Dailies_y2019m02d11.nc\n",
      "ncfiles/R202102Dailies_y2019m02d12.nc\n",
      "ncfiles/R202102Dailies_y2019m02d13.nc\n",
      "ncfiles/R202102Dailies_y2019m02d14.nc\n",
      "ncfiles/R202102Dailies_y2019m02d15.nc\n",
      "ncfiles/R202102Dailies_y2019m02d16.nc\n",
      "ncfiles/R202102Dailies_y2019m02d17.nc\n",
      "ncfiles/R202102Dailies_y2019m02d18.nc\n",
      "ncfiles/R202102Dailies_y2019m02d19.nc\n",
      "ncfiles/R202102Dailies_y2019m02d20.nc\n",
      "ncfiles/R202102Dailies_y2019m02d21.nc\n",
      "ncfiles/R202102Dailies_y2019m02d22.nc\n",
      "ncfiles/R202102Dailies_y2019m02d23.nc\n",
      "ncfiles/R202102Dailies_y2019m02d24.nc\n",
      "ncfiles/R202102Dailies_y2019m02d25.nc\n",
      "ncfiles/R202102Dailies_y2019m02d26.nc\n",
      "ncfiles/R202102Dailies_y2019m02d27.nc\n",
      "ncfiles/R202102Dailies_y2019m02d28.nc\n",
      "ncfiles/R202102Dailies_y2019m03d01.nc\n",
      "ncfiles/R202102Dailies_y2019m03d02.nc\n",
      "ncfiles/R202102Dailies_y2019m03d03.nc\n",
      "ncfiles/R202102Dailies_y2019m03d04.nc\n",
      "ncfiles/R202102Dailies_y2019m03d05.nc\n",
      "ncfiles/R202102Dailies_y2019m03d06.nc\n",
      "ncfiles/R202102Dailies_y2019m03d07.nc\n",
      "ncfiles/R202102Dailies_y2019m03d08.nc\n",
      "ncfiles/R202102Dailies_y2019m03d09.nc\n",
      "ncfiles/R202102Dailies_y2019m03d10.nc\n",
      "ncfiles/R202102Dailies_y2019m03d11.nc\n",
      "ncfiles/R202102Dailies_y2019m03d12.nc\n",
      "ncfiles/R202102Dailies_y2019m03d13.nc\n",
      "ncfiles/R202102Dailies_y2019m03d14.nc\n",
      "ncfiles/R202102Dailies_y2019m03d15.nc\n",
      "ncfiles/R202102Dailies_y2019m03d16.nc\n",
      "ncfiles/R202102Dailies_y2019m03d17.nc\n",
      "ncfiles/R202102Dailies_y2019m03d18.nc\n",
      "ncfiles/R202102Dailies_y2019m03d19.nc\n",
      "ncfiles/R202102Dailies_y2019m03d20.nc\n",
      "ncfiles/R202102Dailies_y2019m03d21.nc\n",
      "ncfiles/R202102Dailies_y2019m03d22.nc\n",
      "ncfiles/R202102Dailies_y2019m03d23.nc\n",
      "ncfiles/R202102Dailies_y2019m03d24.nc\n",
      "ncfiles/R202102Dailies_y2019m03d25.nc\n",
      "ncfiles/R202102Dailies_y2019m03d26.nc\n",
      "ncfiles/R202102Dailies_y2019m03d27.nc\n",
      "ncfiles/R202102Dailies_y2019m03d28.nc\n",
      "ncfiles/R202102Dailies_y2019m03d29.nc\n",
      "ncfiles/R202102Dailies_y2019m03d30.nc\n",
      "ncfiles/R202102Dailies_y2019m03d31.nc\n",
      "ncfiles/R202102Dailies_y2019m04d01.nc\n",
      "ncfiles/R202102Dailies_y2019m04d02.nc\n",
      "ncfiles/R202102Dailies_y2019m04d03.nc\n",
      "ncfiles/R202102Dailies_y2019m04d04.nc\n",
      "ncfiles/R202102Dailies_y2019m04d05.nc\n",
      "ncfiles/R202102Dailies_y2019m04d06.nc\n",
      "ncfiles/R202102Dailies_y2019m04d07.nc\n",
      "ncfiles/R202102Dailies_y2019m04d08.nc\n",
      "ncfiles/R202102Dailies_y2019m04d09.nc\n",
      "ncfiles/R202102Dailies_y2019m04d10.nc\n",
      "ncfiles/R202102Dailies_y2019m04d11.nc\n",
      "ncfiles/R202102Dailies_y2019m04d12.nc\n",
      "ncfiles/R202102Dailies_y2019m04d13.nc\n",
      "ncfiles/R202102Dailies_y2019m04d14.nc\n",
      "ncfiles/R202102Dailies_y2019m04d15.nc\n",
      "ncfiles/R202102Dailies_y2019m04d16.nc\n",
      "ncfiles/R202102Dailies_y2019m04d17.nc\n",
      "ncfiles/R202102Dailies_y2019m04d18.nc\n",
      "ncfiles/R202102Dailies_y2019m04d19.nc\n",
      "ncfiles/R202102Dailies_y2019m04d20.nc\n",
      "ncfiles/R202102Dailies_y2019m04d21.nc\n",
      "ncfiles/R202102Dailies_y2019m04d22.nc\n",
      "ncfiles/R202102Dailies_y2019m04d23.nc\n",
      "ncfiles/R202102Dailies_y2019m04d24.nc\n",
      "ncfiles/R202102Dailies_y2019m04d25.nc\n",
      "ncfiles/R202102Dailies_y2019m04d26.nc\n",
      "ncfiles/R202102Dailies_y2019m04d27.nc\n",
      "ncfiles/R202102Dailies_y2019m04d28.nc\n",
      "ncfiles/R202102Dailies_y2019m04d29.nc\n",
      "ncfiles/R202102Dailies_y2019m04d30.nc\n",
      "ncfiles/R202102Dailies_y2019m05d01.nc\n",
      "ncfiles/R202102Dailies_y2019m05d02.nc\n",
      "ncfiles/R202102Dailies_y2019m05d03.nc\n",
      "ncfiles/R202102Dailies_y2019m05d04.nc\n",
      "ncfiles/R202102Dailies_y2019m05d05.nc\n",
      "ncfiles/R202102Dailies_y2019m05d06.nc\n",
      "ncfiles/R202102Dailies_y2019m05d07.nc\n",
      "ncfiles/R202102Dailies_y2019m05d08.nc\n",
      "ncfiles/R202102Dailies_y2019m05d09.nc\n",
      "ncfiles/R202102Dailies_y2019m05d10.nc\n",
      "ncfiles/R202102Dailies_y2019m05d11.nc\n",
      "ncfiles/R202102Dailies_y2019m05d12.nc\n",
      "ncfiles/R202102Dailies_y2019m05d13.nc\n",
      "ncfiles/R202102Dailies_y2019m05d14.nc\n",
      "ncfiles/R202102Dailies_y2019m05d15.nc\n",
      "ncfiles/R202102Dailies_y2019m05d16.nc\n",
      "ncfiles/R202102Dailies_y2019m05d17.nc\n",
      "ncfiles/R202102Dailies_y2019m05d18.nc\n",
      "ncfiles/R202102Dailies_y2019m05d19.nc\n",
      "ncfiles/R202102Dailies_y2019m05d20.nc\n",
      "ncfiles/R202102Dailies_y2019m05d21.nc\n",
      "ncfiles/R202102Dailies_y2019m05d22.nc\n",
      "ncfiles/R202102Dailies_y2019m05d23.nc\n",
      "ncfiles/R202102Dailies_y2019m05d24.nc\n",
      "ncfiles/R202102Dailies_y2019m05d25.nc\n",
      "ncfiles/R202102Dailies_y2019m05d26.nc\n",
      "ncfiles/R202102Dailies_y2019m05d27.nc\n",
      "ncfiles/R202102Dailies_y2019m05d28.nc\n",
      "ncfiles/R202102Dailies_y2019m05d29.nc\n",
      "ncfiles/R202102Dailies_y2019m05d30.nc\n",
      "ncfiles/R202102Dailies_y2019m05d31.nc\n",
      "ncfiles/R202102Dailies_y2019m06d01.nc\n",
      "ncfiles/R202102Dailies_y2019m06d02.nc\n",
      "ncfiles/R202102Dailies_y2019m06d03.nc\n",
      "ncfiles/R202102Dailies_y2019m06d04.nc\n",
      "ncfiles/R202102Dailies_y2019m06d05.nc\n",
      "ncfiles/R202102Dailies_y2019m06d06.nc\n",
      "ncfiles/R202102Dailies_y2019m06d07.nc\n",
      "ncfiles/R202102Dailies_y2019m06d08.nc\n",
      "ncfiles/R202102Dailies_y2019m06d09.nc\n",
      "ncfiles/R202102Dailies_y2019m06d10.nc\n",
      "ncfiles/R202102Dailies_y2019m06d11.nc\n",
      "ncfiles/R202102Dailies_y2019m06d12.nc\n",
      "ncfiles/R202102Dailies_y2019m06d13.nc\n",
      "ncfiles/R202102Dailies_y2019m06d14.nc\n",
      "ncfiles/R202102Dailies_y2019m06d15.nc\n",
      "ncfiles/R202102Dailies_y2019m06d16.nc\n",
      "ncfiles/R202102Dailies_y2019m06d17.nc\n",
      "ncfiles/R202102Dailies_y2019m06d18.nc\n",
      "ncfiles/R202102Dailies_y2019m06d19.nc\n",
      "ncfiles/R202102Dailies_y2019m06d20.nc\n",
      "ncfiles/R202102Dailies_y2019m06d21.nc\n",
      "ncfiles/R202102Dailies_y2019m06d22.nc\n",
      "ncfiles/R202102Dailies_y2019m06d23.nc\n",
      "ncfiles/R202102Dailies_y2019m06d24.nc\n",
      "ncfiles/R202102Dailies_y2019m06d25.nc\n",
      "ncfiles/R202102Dailies_y2019m06d26.nc\n",
      "ncfiles/R202102Dailies_y2019m06d27.nc\n",
      "ncfiles/R202102Dailies_y2019m06d28.nc\n",
      "ncfiles/R202102Dailies_y2019m06d29.nc\n",
      "ncfiles/R202102Dailies_y2019m06d30.nc\n",
      "ncfiles/R202102Dailies_y2019m07d01.nc\n",
      "ncfiles/R202102Dailies_y2019m07d02.nc\n",
      "ncfiles/R202102Dailies_y2019m07d03.nc\n",
      "ncfiles/R202102Dailies_y2019m07d04.nc\n",
      "ncfiles/R202102Dailies_y2019m07d05.nc\n",
      "ncfiles/R202102Dailies_y2019m07d06.nc\n",
      "ncfiles/R202102Dailies_y2019m07d07.nc\n",
      "ncfiles/R202102Dailies_y2019m07d08.nc\n",
      "ncfiles/R202102Dailies_y2019m07d09.nc\n",
      "ncfiles/R202102Dailies_y2019m07d10.nc\n",
      "ncfiles/R202102Dailies_y2019m07d11.nc\n",
      "ncfiles/R202102Dailies_y2019m07d12.nc\n",
      "ncfiles/R202102Dailies_y2019m07d13.nc\n",
      "ncfiles/R202102Dailies_y2019m07d14.nc\n",
      "ncfiles/R202102Dailies_y2019m07d15.nc\n",
      "ncfiles/R202102Dailies_y2019m07d16.nc\n",
      "ncfiles/R202102Dailies_y2019m07d17.nc\n",
      "ncfiles/R202102Dailies_y2019m07d18.nc\n",
      "ncfiles/R202102Dailies_y2019m07d19.nc\n",
      "ncfiles/R202102Dailies_y2019m07d20.nc\n",
      "ncfiles/R202102Dailies_y2019m07d21.nc\n",
      "ncfiles/R202102Dailies_y2019m07d22.nc\n",
      "ncfiles/R202102Dailies_y2019m07d23.nc\n",
      "ncfiles/R202102Dailies_y2019m07d24.nc\n",
      "ncfiles/R202102Dailies_y2019m07d25.nc\n",
      "ncfiles/R202102Dailies_y2019m07d26.nc\n",
      "ncfiles/R202102Dailies_y2019m07d27.nc\n",
      "ncfiles/R202102Dailies_y2019m07d28.nc\n",
      "ncfiles/R202102Dailies_y2019m07d29.nc\n",
      "ncfiles/R202102Dailies_y2019m07d30.nc\n",
      "ncfiles/R202102Dailies_y2019m07d31.nc\n",
      "ncfiles/R202102Dailies_y2019m08d01.nc\n",
      "ncfiles/R202102Dailies_y2019m08d02.nc\n",
      "ncfiles/R202102Dailies_y2019m08d03.nc\n",
      "ncfiles/R202102Dailies_y2019m08d04.nc\n",
      "ncfiles/R202102Dailies_y2019m08d05.nc\n",
      "ncfiles/R202102Dailies_y2019m08d06.nc\n",
      "ncfiles/R202102Dailies_y2019m08d07.nc\n",
      "ncfiles/R202102Dailies_y2019m08d08.nc\n",
      "ncfiles/R202102Dailies_y2019m08d09.nc\n",
      "ncfiles/R202102Dailies_y2019m08d10.nc\n",
      "ncfiles/R202102Dailies_y2019m08d11.nc\n",
      "ncfiles/R202102Dailies_y2019m08d12.nc\n",
      "ncfiles/R202102Dailies_y2019m08d13.nc\n",
      "ncfiles/R202102Dailies_y2019m08d14.nc\n",
      "ncfiles/R202102Dailies_y2019m08d15.nc\n",
      "ncfiles/R202102Dailies_y2019m08d16.nc\n",
      "ncfiles/R202102Dailies_y2019m08d17.nc\n",
      "ncfiles/R202102Dailies_y2019m08d18.nc\n",
      "ncfiles/R202102Dailies_y2019m08d19.nc\n",
      "ncfiles/R202102Dailies_y2019m08d20.nc\n",
      "ncfiles/R202102Dailies_y2019m08d21.nc\n",
      "ncfiles/R202102Dailies_y2019m08d22.nc\n",
      "ncfiles/R202102Dailies_y2019m08d23.nc\n",
      "ncfiles/R202102Dailies_y2019m08d24.nc\n",
      "ncfiles/R202102Dailies_y2019m08d25.nc\n",
      "ncfiles/R202102Dailies_y2019m08d26.nc\n",
      "ncfiles/R202102Dailies_y2019m08d27.nc\n",
      "ncfiles/R202102Dailies_y2019m08d28.nc\n",
      "ncfiles/R202102Dailies_y2019m08d29.nc\n",
      "ncfiles/R202102Dailies_y2019m08d30.nc\n",
      "ncfiles/R202102Dailies_y2019m08d31.nc\n",
      "ncfiles/R202102Dailies_y2019m09d01.nc\n",
      "ncfiles/R202102Dailies_y2019m09d02.nc\n",
      "ncfiles/R202102Dailies_y2019m09d03.nc\n",
      "ncfiles/R202102Dailies_y2019m09d04.nc\n",
      "ncfiles/R202102Dailies_y2019m09d05.nc\n",
      "ncfiles/R202102Dailies_y2019m09d06.nc\n",
      "ncfiles/R202102Dailies_y2019m09d07.nc\n",
      "ncfiles/R202102Dailies_y2019m09d08.nc\n",
      "ncfiles/R202102Dailies_y2019m09d09.nc\n",
      "ncfiles/R202102Dailies_y2019m09d10.nc\n",
      "ncfiles/R202102Dailies_y2019m09d11.nc\n",
      "ncfiles/R202102Dailies_y2019m09d12.nc\n",
      "ncfiles/R202102Dailies_y2019m09d13.nc\n",
      "ncfiles/R202102Dailies_y2019m09d14.nc\n",
      "ncfiles/R202102Dailies_y2019m09d15.nc\n",
      "ncfiles/R202102Dailies_y2019m09d16.nc\n",
      "ncfiles/R202102Dailies_y2019m09d17.nc\n",
      "ncfiles/R202102Dailies_y2019m09d18.nc\n",
      "ncfiles/R202102Dailies_y2019m09d19.nc\n",
      "ncfiles/R202102Dailies_y2019m09d20.nc\n",
      "ncfiles/R202102Dailies_y2019m09d21.nc\n",
      "ncfiles/R202102Dailies_y2019m09d22.nc\n",
      "ncfiles/R202102Dailies_y2019m09d23.nc\n",
      "ncfiles/R202102Dailies_y2019m09d24.nc\n",
      "ncfiles/R202102Dailies_y2019m09d25.nc\n",
      "ncfiles/R202102Dailies_y2019m09d26.nc\n",
      "ncfiles/R202102Dailies_y2019m09d27.nc\n",
      "ncfiles/R202102Dailies_y2019m09d28.nc\n",
      "ncfiles/R202102Dailies_y2019m09d29.nc\n",
      "ncfiles/R202102Dailies_y2019m09d30.nc\n",
      "ncfiles/R202102Dailies_y2019m10d01.nc\n",
      "ncfiles/R202102Dailies_y2019m10d02.nc\n",
      "ncfiles/R202102Dailies_y2019m10d03.nc\n",
      "ncfiles/R202102Dailies_y2019m10d04.nc\n",
      "ncfiles/R202102Dailies_y2019m10d05.nc\n",
      "ncfiles/R202102Dailies_y2019m10d06.nc\n",
      "ncfiles/R202102Dailies_y2019m10d07.nc\n",
      "ncfiles/R202102Dailies_y2019m10d08.nc\n",
      "ncfiles/R202102Dailies_y2019m10d09.nc\n",
      "ncfiles/R202102Dailies_y2019m10d10.nc\n",
      "ncfiles/R202102Dailies_y2019m10d11.nc\n",
      "ncfiles/R202102Dailies_y2019m10d12.nc\n",
      "ncfiles/R202102Dailies_y2019m10d13.nc\n",
      "ncfiles/R202102Dailies_y2019m10d14.nc\n",
      "ncfiles/R202102Dailies_y2019m10d15.nc\n",
      "ncfiles/R202102Dailies_y2019m10d16.nc\n",
      "ncfiles/R202102Dailies_y2019m10d17.nc\n",
      "ncfiles/R202102Dailies_y2019m10d18.nc\n",
      "ncfiles/R202102Dailies_y2019m10d19.nc\n",
      "ncfiles/R202102Dailies_y2019m10d20.nc\n",
      "ncfiles/R202102Dailies_y2019m10d21.nc\n",
      "ncfiles/R202102Dailies_y2019m10d22.nc\n",
      "ncfiles/R202102Dailies_y2019m10d23.nc\n",
      "ncfiles/R202102Dailies_y2019m10d24.nc\n",
      "ncfiles/R202102Dailies_y2019m10d25.nc\n",
      "ncfiles/R202102Dailies_y2019m10d26.nc\n",
      "ncfiles/R202102Dailies_y2019m10d27.nc\n",
      "ncfiles/R202102Dailies_y2019m10d28.nc\n",
      "ncfiles/R202102Dailies_y2019m10d29.nc\n",
      "ncfiles/R202102Dailies_y2019m10d30.nc\n",
      "ncfiles/R202102Dailies_y2019m10d31.nc\n",
      "ncfiles/R202102Dailies_y2019m11d01.nc\n",
      "ncfiles/R202102Dailies_y2019m11d02.nc\n",
      "ncfiles/R202102Dailies_y2019m11d03.nc\n",
      "ncfiles/R202102Dailies_y2019m11d04.nc\n",
      "ncfiles/R202102Dailies_y2019m11d05.nc\n",
      "ncfiles/R202102Dailies_y2019m11d06.nc\n",
      "ncfiles/R202102Dailies_y2019m11d07.nc\n",
      "ncfiles/R202102Dailies_y2019m11d08.nc\n",
      "ncfiles/R202102Dailies_y2019m11d09.nc\n",
      "ncfiles/R202102Dailies_y2019m11d10.nc\n",
      "ncfiles/R202102Dailies_y2019m11d11.nc\n",
      "ncfiles/R202102Dailies_y2019m11d12.nc\n",
      "ncfiles/R202102Dailies_y2019m11d13.nc\n",
      "ncfiles/R202102Dailies_y2019m11d14.nc\n",
      "ncfiles/R202102Dailies_y2019m11d15.nc\n",
      "ncfiles/R202102Dailies_y2019m11d16.nc\n",
      "ncfiles/R202102Dailies_y2019m11d17.nc\n",
      "ncfiles/R202102Dailies_y2019m11d18.nc\n",
      "ncfiles/R202102Dailies_y2019m11d19.nc\n",
      "ncfiles/R202102Dailies_y2019m11d20.nc\n",
      "ncfiles/R202102Dailies_y2019m11d21.nc\n",
      "ncfiles/R202102Dailies_y2019m11d22.nc\n",
      "ncfiles/R202102Dailies_y2019m11d23.nc\n",
      "ncfiles/R202102Dailies_y2019m11d24.nc\n",
      "ncfiles/R202102Dailies_y2019m11d25.nc\n",
      "ncfiles/R202102Dailies_y2019m11d26.nc\n",
      "ncfiles/R202102Dailies_y2019m11d27.nc\n",
      "ncfiles/R202102Dailies_y2019m11d28.nc\n",
      "ncfiles/R202102Dailies_y2019m11d29.nc\n",
      "ncfiles/R202102Dailies_y2019m11d30.nc\n",
      "ncfiles/R202102Dailies_y2019m12d01.nc\n",
      "ncfiles/R202102Dailies_y2019m12d02.nc\n",
      "ncfiles/R202102Dailies_y2019m12d03.nc\n",
      "ncfiles/R202102Dailies_y2019m12d04.nc\n",
      "ncfiles/R202102Dailies_y2019m12d05.nc\n",
      "ncfiles/R202102Dailies_y2019m12d06.nc\n",
      "ncfiles/R202102Dailies_y2019m12d07.nc\n",
      "ncfiles/R202102Dailies_y2019m12d08.nc\n",
      "ncfiles/R202102Dailies_y2019m12d09.nc\n",
      "ncfiles/R202102Dailies_y2019m12d10.nc\n",
      "ncfiles/R202102Dailies_y2019m12d11.nc\n",
      "ncfiles/R202102Dailies_y2019m12d12.nc\n",
      "ncfiles/R202102Dailies_y2019m12d13.nc\n",
      "ncfiles/R202102Dailies_y2019m12d14.nc\n",
      "ncfiles/R202102Dailies_y2019m12d15.nc\n",
      "ncfiles/R202102Dailies_y2019m12d16.nc\n",
      "ncfiles/R202102Dailies_y2019m12d17.nc\n",
      "ncfiles/R202102Dailies_y2019m12d18.nc\n",
      "ncfiles/R202102Dailies_y2019m12d19.nc\n",
      "ncfiles/R202102Dailies_y2019m12d20.nc\n",
      "ncfiles/R202102Dailies_y2019m12d21.nc\n",
      "ncfiles/R202102Dailies_y2019m12d22.nc\n",
      "ncfiles/R202102Dailies_y2019m12d23.nc\n",
      "ncfiles/R202102Dailies_y2019m12d24.nc\n",
      "ncfiles/R202102Dailies_y2019m12d25.nc\n",
      "ncfiles/R202102Dailies_y2019m12d26.nc\n",
      "ncfiles/R202102Dailies_y2019m12d27.nc\n",
      "ncfiles/R202102Dailies_y2019m12d28.nc\n",
      "ncfiles/R202102Dailies_y2019m12d29.nc\n",
      "ncfiles/R202102Dailies_y2019m12d30.nc\n",
      "ncfiles/R202102Dailies_y2019m12d31.nc\n"
     ]
    }
   ],
   "source": [
    "flows = {}\n",
    "for name in names:\n",
    "    print (name)\n",
    "    if rivers_for_watershed[name]['secondary'] == 'False':\n",
    "        print ('no secondary')\n",
    "        flows[name] = do_a_pair(name, watershed_from_river, startdate, enddate, \n",
    "                                rivers_for_watershed[name]['primary'], False)\n",
    "    elif name == 'fraser':\n",
    "        flows['Fraser'], flows['nonFraser'] = do_fraser(watershed_from_river, startdate, enddate,\n",
    "                               rivers_for_watershed[name]['primary'],\n",
    "                               rivers_for_watershed[name]['secondary'])\n",
    "    else:\n",
    "        flows[name] = do_a_pair(name, watershed_from_river, startdate, enddate,\n",
    "                                rivers_for_watershed[name]['primary'], True,\n",
    "                               rivers_for_watershed[name]['secondary'])\n",
    "\n",
    "for day in arrow.Arrow.range('day', startdate, enddate):\n",
    "    runoff = np.zeros((horz_area.shape[0], horz_area.shape[1]))\n",
    "    run_depth = np.ones_like(runoff)\n",
    "    run_temp = np.empty_like(runoff)\n",
    "    for name in names:\n",
    "        if name == 'fraser':\n",
    "            for key in prop_dict[name]:\n",
    "                if \"Fraser\" in key:\n",
    "                    flux = flows['Fraser'][flows['Fraser'].index == day.naive]['Daily Flow'][0]\n",
    "                    subarea = fraserratio\n",
    "                else:\n",
    "                    flux = flows['nonFraser'][flows['nonFraser'].index == day.naive]['Daily Flow'][0]\n",
    "                    subarea = 1 - fraserratio\n",
    "        \n",
    "                river = prop_dict['fraser'][key]\n",
    "                runoff = rivertools.fill_runoff_array(flux*river['prop']/subarea, river['i'],\n",
    "                          river['di'], river['j'], river['dj'], river['depth'], runoff, \n",
    "                          run_depth, horz_area)[0]\n",
    "        else:\n",
    "            flowtoday = flows[name][flows[name].index == day.naive]['Daily Flow'][0]\n",
    "            runoff, run_depth, run_temp = rivertools.put_watershed_into_runoff('constant', horz_area,\n",
    "                                            flowtoday, runoff, run_depth, run_temp,\n",
    "                                            prop_dict[name])\n",
    "            \n",
    "    write_file(day, runoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathy = xr.open_dataset('../../../grid/bathymetry_201702.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imin, imax = 0, 898\n",
    "jmin, jmax = 0, 394\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 9))\n",
    "ax.contourf(bathy.Bathymetry[imin:imax, jmin:jmax], cmap='winter_r')\n",
    "for i in range(imin, imax):\n",
    "    for j in range(jmin, jmax):\n",
    "        flux = runoff[i, j]\n",
    "        if flux > 0 :\n",
    "            plt.scatter(j - jmin, i - imin, s=flux*1000, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = xr.open_dataset('/results/forcing/rivers/R201702DFraCElse_y2018m03d31.nc')\n",
    "readitin = xr.open_dataset('ncfiles/R202102Dailies_y2018m03d31.nc')\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 9))\n",
    "for ax in axs:\n",
    "    ax.contourf(bathy.Bathymetry[imin:imax, jmin:jmax], cmap='winter_r')\n",
    "for i in range(imin, imax):\n",
    "    for j in range(jmin, jmax):\n",
    "        flux = fluxarray[i, j]\n",
    "        if flux > 0 :\n",
    "            axs[1].scatter(j - jmin, i - imin, s=flux*1000, color='r')\n",
    "            axs[0].scatter(j - jmin, i - imin, s=climatearray[i, j]*1000, color='r')\n",
    "            if flux > climatearray[i, j]:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(flux-climatearray[i, j])*1000, color='r')\n",
    "            else:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(climatearray[i, j]-flux)*1000, color='b')\n",
    "            \n",
    "readitin.close()\n",
    "climate.close()\n",
    "fig.suptitle('March 31, 2018');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readitin = xr.open_dataset('ncfiles/R202102Dailies_y2018m05d31.nc')\n",
    "climate = xr.open_dataset('/results/forcing/rivers/R201702DFraCElse_y2018m05d31.nc')\n",
    "fluxarray = readitin.rorunoff[0]\n",
    "climatearray = climate.rorunoff[0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 9))\n",
    "fig.suptitle('May 31, 2018')\n",
    "for ax in axs:\n",
    "    ax.contourf(bathy.Bathymetry[imin:imax, jmin:jmax], cmap='winter_r')\n",
    "for i in range(imin, imax):\n",
    "    for j in range(jmin, jmax):\n",
    "        flux = fluxarray[i, j]\n",
    "        if flux > 0 :\n",
    "            axs[1].scatter(j - jmin, i - imin, s=flux*1000, color='r')\n",
    "            axs[0].scatter(j - jmin, i - imin, s=climatearray[i, j]*1000, color='r')\n",
    "            if flux > climatearray[i, j]:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(flux-climatearray[i, j])*1000, color='r')\n",
    "            else:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(climatearray[i, j]-flux)*1000, color='b')\n",
    "            \n",
    "readitin.close()\n",
    "climate.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readitin = xr.open_dataset('ncfiles/R202102Dailies_y2018m08d31.nc')\n",
    "climate = xr.open_dataset('/results/forcing/rivers/R201702DFraCElse_y2018m08d31.nc')\n",
    "fluxarray = readitin.rorunoff[0]\n",
    "climatearray = climate.rorunoff[0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 9))\n",
    "fig.suptitle('August 31, 2018')\n",
    "for ax in axs:\n",
    "    ax.contourf(bathy.Bathymetry[imin:imax, jmin:jmax], cmap='winter_r')\n",
    "for i in range(imin, imax):\n",
    "    for j in range(jmin, jmax):\n",
    "        flux = fluxarray[i, j]\n",
    "        if flux > 0 :\n",
    "            axs[1].scatter(j - jmin, i - imin, s=flux*1000, color='r')\n",
    "            axs[0].scatter(j - jmin, i - imin, s=climatearray[i, j]*1000, color='r')\n",
    "            if flux > climatearray[i, j]:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(flux-climatearray[i, j])*1000, color='r')\n",
    "            else:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(climatearray[i, j]-flux)*1000, color='b')\n",
    "            \n",
    "readitin.close()\n",
    "climate.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readitin = xr.open_dataset('ncfiles/R202102Dailies_y2018m12d31.nc')\n",
    "climate = xr.open_dataset('/results/forcing/rivers/R201702DFraCElse_y2018m12d31.nc')\n",
    "fluxarray = readitin.rorunoff[0]\n",
    "climatearray = climate.rorunoff[0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 9))\n",
    "fig.suptitle('December 31, 2018')\n",
    "for ax in axs:\n",
    "    ax.contourf(bathy.Bathymetry[imin:imax, jmin:jmax], cmap='winter_r')\n",
    "for i in range(imin, imax):\n",
    "    for j in range(jmin, jmax):\n",
    "        flux = fluxarray[i, j]\n",
    "        if flux > 0 :\n",
    "            axs[1].scatter(j - jmin, i - imin, s=flux*1000, color='r')\n",
    "            axs[0].scatter(j - jmin, i - imin, s=climatearray[i, j]*1000, color='r')\n",
    "            if flux > climatearray[i, j]:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(flux-climatearray[i, j])*1000, color='r')\n",
    "            else:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(climatearray[i, j]-flux)*1000, color='b')\n",
    "            \n",
    "readitin.close()\n",
    "climate.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014: All blue, all the time?  Not quite, PS is red is December and May."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readitin = xr.open_dataset('ncfiles/R202102Dailies_y2014m11d01.nc')\n",
    "climate = xr.open_dataset('/results/forcing/rivers/R201702DFraCElse_y2014m11d01.nc')\n",
    "fluxarray = readitin.rorunoff[0]\n",
    "climatearray = climate.rorunoff[0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 9))\n",
    "fig.suptitle('November 1, 2014')\n",
    "for ax in axs:\n",
    "    ax.contourf(bathy.Bathymetry[imin:imax, jmin:jmax], cmap='winter_r')\n",
    "for i in range(imin, imax):\n",
    "    for j in range(jmin, jmax):\n",
    "        flux = fluxarray[i, j]\n",
    "        if flux > 0 :\n",
    "            axs[1].scatter(j - jmin, i - imin, s=flux*1000, color='r')\n",
    "            axs[0].scatter(j - jmin, i - imin, s=climatearray[i, j]*1000, color='r')\n",
    "            if flux > climatearray[i, j]:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(flux-climatearray[i, j])*1000, color='r')\n",
    "            else:\n",
    "                axs[2].scatter(j - jmin, i-imin, s=(climatearray[i, j]-flux)*1000, color='b')\n",
    "            \n",
    "readitin.close()\n",
    "climate.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
