{
 "metadata": {
  "name": "",
  "signature": "sha256:81d6d9de5f3a7c0624a9583c32971393e7c8d94e69ae5ead8c806f9d02802902"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook reads storm surge data from a NOAA website:\n",
      "http://www.nws.noaa.gov/mdl/etsurge/index.php?page=stn&region=wc&datum=mllw&list=&map=0-48&type=both&stn=waneah"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Typically, this website provides 5.5 days of data and begins with observations from the previous day. Only days with a full 24 hours of data are saved into netcdf files. Forecasts and observations are separated.\n",
      "\n",
      "If this notebook is executed on October 29 in the morning (local time), we should end up with the following files. \n",
      "\n",
      "Forecasts:\n",
      "* /ocean/nsoontie/MEOAPAR/sshNeahBay/fcst/ssh_y2014m10d29.nc\n",
      "* /ocean/nsoontie/MEOAPAR/sshNeahBay/fcst/ssh_y2014m10d30.nc\n",
      "* /ocean/nsoontie/MEOAPAR/sshNeahBay/fcst/ssh_y2014m10d31.nc\n",
      "* /ocean/nsoontie/MEOAPAR/sshNeahBay/fcst/ssh_y2014m11d01.nc\n",
      "\n",
      "Observations:\n",
      "* /ocean/nsoontie/MEOAPAR/sshNeahBay/obs/ssh_y2014m10d28.nc\n",
      "\n",
      "Original data :\n",
      "* /ocean/nsoontie/MEOAPAR/sshNeahBay/txt/sshNB_2014-10-29.txt\n",
      "\n",
      "If the notebook is executed later in the day (after 00:00 UTC?), we could end up with a different set of files (I think the observations switch from 00Z Oct 28 to 6Z Oct 28).  \n",
      "\n",
      "The Neah Bay website doesn't indicate the year in its timestamps so I have specified the year. This might not work very well when we move forward to automation. I will think about how to fix this...\n",
      "\n",
      "\n",
      "Note: If forecasts change from day to day then the old forecasts file will be overwritten."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "\n",
      "import netCDF4 as nc\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "from salishsea_tools import (\n",
      "    nc_tools)\n",
      "import pytz, datetime\n",
      "import os\n",
      "import urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "from StringIO import StringIO\n",
      "import pandas as pd\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plan of notebook:\n",
      "\n",
      "1. Read website.\n",
      "    * Parse out table\n",
      "    * Save txt file for future reference  - use datestring of generation time for file name?\n",
      "2. Generate storm surge \n",
      "    * Flag for predictions or observations\n",
      "    * Two ways of calculating surge - Obs-Tides or Fcast - Tides\n",
      "    * Can only use a full day of data - no partial days\n",
      "3. Save in NETCDF\n",
      "    * predictions go to one directory, obsevations to another\n",
      "    * prediction vs observation in the metadata too?\n",
      "    * include path to text file in metadata\n",
      "    \n",
      "First list some functions to use"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#need to convert feet to metres\n",
      "def feet_to_metres(feet):\n",
      "    metres = feet*0.3048\n",
      "    return metres"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#need to convert their times into datetime objects. Their dates don't include a year. \n",
      "#I need to think about what to do when the year switches...!\n",
      "def to_datetime(datestr,year):\n",
      "    \"\"\" converts the string given by datestr to a datetime object.\n",
      "    The year is an argument because the datestr in the NOAA data doesn't have a year.\n",
      "    Times are in UTC/GMT.\n",
      "    returns a datetime representation of datestr\"\"\"\n",
      "    dt = datetime.datetime.strptime(datestr,'%m/%d %HZ')\n",
      "    dt =dt.replace(year=year)\n",
      "    dt=dt.replace(tzinfo=pytz.timezone('UTC'))\n",
      "    return dt\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_full_days(dates):\n",
      "    \"\"\"returns a list of days that have a full 24 hour data set.\"\"\"\n",
      "    \n",
      "    #check if first day is a full day\n",
      "    tc,ds= isolate_day(dates[0],dates)\n",
      "    if ds.shape[0] == tc.shape[0]:\n",
      "        start = dates[0]\n",
      "    else:\n",
      "        start = dates[0] +datetime.timedelta(days=1)\n",
      "    start=datetime.datetime(start.year,start.month, start.day,tzinfo=pytz.timezone('UTC'))\n",
      "\n",
      "    #check if last day is a full day\n",
      "    tc,ds = isolate_day(dates[-1],dates)\n",
      "    if ds.shape[0] == tc.shape[0]:\n",
      "        end = dates[-1]\n",
      "    else:\n",
      "        end = dates[-1] -datetime.timedelta(days=1)\n",
      "    end=datetime.datetime(end.year,end.month, end.day,tzinfo=pytz.timezone('UTC'))\n",
      "    \n",
      "    #list of dates that are full\n",
      "    dates_list = [start +datetime.timedelta(days=i) for i in range((end-start).days+1)]\n",
      "    return dates_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def isolate_day(day, dates):\n",
      "    \"\"\"returns array of time_counter and datetime objects over a 24 hour period covering one full day\"\"\"\n",
      "    tc=np.arange(24)\n",
      "    dates_return=[];\n",
      "    for t in dates:\n",
      "        if t.month==day.month:\n",
      "            if t.day==day.day:\n",
      "                dates_return.append(t);\n",
      "    return tc, np.array(dates_return)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def retrieve_surge(day,dates, data):\n",
      "    \"\"\"gathers the surge information for a single day. \n",
      "    returns the surges in meteres, an array with time_counter and a flag indicating if this day was a forecast\"\"\"\n",
      "    #initialize forecast flag and surge array\n",
      "    forecast_flag=0; surge=[]\n",
      "    #grab list of times on this day.\n",
      "    tc,ds= isolate_day(day,dates)\n",
      "    \n",
      "    for d in ds:\n",
      "        #convert datetime to string for comparing with times in data\n",
      "        daystr = d.strftime('%m/%d %HZ')\n",
      "        tide=data.tide[data.date==daystr].item()\n",
      "        obs=data.obs[data.date==daystr].item()\n",
      "        fcst = data.fcst[data.date==daystr].item()\n",
      "        if obs == 99.90:\n",
      "            #fall daylight savings\n",
      "            if fcst==99.90:\n",
      "                #if surge is empty, just append 0\n",
      "                if not surge:\n",
      "                    surge.append(0)\n",
      "                else:  \n",
      "                #otherwise append previous value \n",
      "                    surge.append(surge[-1])\n",
      "            else:\n",
      "                surge.append(feet_to_metres(fcst-tide))\n",
      "                forecast_flag=1\n",
      "        else:\n",
      "            surge.append(feet_to_metres(obs-tide))\n",
      "    \n",
      "    return surge, tc,  forecast_flag"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_netcdf(day,tc,surges,forecast_flag,textfile):\n",
      "    \"\"\"saves the surge for a given day in a netcdf file\"\"\" \n",
      "    \n",
      "    daystr = 'ssh_{}.nc'.format(day.strftime('y%Ym%md%d'))\n",
      "    if forecast_flag:\n",
      "        savstr = os.path.join(SAVE_PATH,'fcst',daystr)\n",
      "        comment = 'Prediction from Neah Bay storm surge website'\n",
      "    else:\n",
      "        savstr = os.path.join(SAVE_PATH,'obs',daystr)\n",
      "        comment = 'Observation from Neah Bay storm surge website'\n",
      "    #open netcdf file\n",
      "    ssh_file = nc.Dataset(savstr, 'w')\n",
      "    nc_tools.init_dataset_attrs(\n",
      "    ssh_file, \n",
      "    title='Neah Bay SSH hourly values', \n",
      "    notebook_name='', \n",
      "    nc_filepath=savstr,\n",
      "    comment=comment)\n",
      "    ssh_file.source=textfile\n",
      "\n",
      "    #dimensions\n",
      "    ssh_file.createDimension('xbT', lengthj*r)\n",
      "    ssh_file.createDimension('yb', 1)\n",
      "    ssh_file.createDimension('time_counter', None)\n",
      "    # variables\n",
      "    # time_counter\n",
      "    time_counter = ssh_file.createVariable('time_counter', 'float32', ('time_counter'))\n",
      "    time_counter.long_name = 'Time axis'\n",
      "    time_counter.axis = 'T'\n",
      "    time_counter.units = 'hour since 00:00:00 on ' +day.strftime('%Y-%m-%d')\n",
      "    # nav_lat and nav_lon\n",
      "    nav_lat = ssh_file.createVariable('nav_lat','float32',('yb','xbT'))\n",
      "    nav_lat.long_name = 'Latitude'\n",
      "    nav_lat.units = 'degrees_north'\n",
      "    nav_lon = ssh_file.createVariable('nav_lon','float32',('yb','xbT'))\n",
      "    nav_lon.long_name = 'Longitude'\n",
      "    nav_lon.units = 'degrees_east'\n",
      "    # ssh\n",
      "    sossheig = ssh_file.createVariable('sossheig', 'float32', \n",
      "                               ('time_counter','yb','xbT'), zlib=True)\n",
      "    sossheig.units = 'm'\n",
      "    sossheig.long_name = 'Sea surface height'   \n",
      "    sossheig.coordinates = 'nav_lon nav_lat time_counter'\n",
      "    sossheig.grid = 'SalishSea2'\n",
      "    # vobtcrtx, vobtcrty\n",
      "    vobtcrtx = ssh_file.createVariable('vobtcrtx', 'float32',\n",
      "                                   ('time_counter','yb','xbT'), zlib=True)\n",
      "    vobtcrtx.units = 'm/s'\n",
      "    vobtcrtx.long_name = 'Barotropic U Velocity- ZEROD'   \n",
      "    vobtcrtx.grid = 'SalishSea2'\n",
      "    vobtcrty = ssh_file.createVariable('vobtcrty', 'float32',\n",
      "                                   ('time_counter','yb','xbT'), zlib=True)\n",
      "    vobtcrty.units = 'm/s'\n",
      "    vobtcrty.long_name = 'Barotropic V Velocity- ZEROD'   \n",
      "    vobtcrty.grid = 'SalishSea2'\n",
      "    # nbidta, ndjdta, ndrdta\n",
      "    nbidta = ssh_file.createVariable('nbidta', 'int32' , ('yb','xbT'), zlib=True)\n",
      "    nbidta.long_name = 'i grid position'\n",
      "    nbidta.units = 1\n",
      "    nbjdta = ssh_file.createVariable('nbjdta', 'int32' , ('yb','xbT'), zlib=True)\n",
      "    nbjdta.long_name = 'j grid position'\n",
      "    nbjdta.units = 1\n",
      "    nbrdta = ssh_file.createVariable('nbrdta', 'int32' , ('yb','xbT'), zlib=True)\n",
      "    nbrdta.long_name = 'position from boundary'\n",
      "    nbrdta.units = 1\n",
      "    \n",
      "    for ir in range(0,r):\n",
      "        nav_lat[0,ir*lengthj:(ir+1)*lengthj] = lat[startj:endj,ir]\n",
      "        nav_lon[0,ir*lengthj:(ir+1)*lengthj] = lon[startj:endj,ir]\n",
      "        nbidta[0,ir*lengthj:(ir+1)*lengthj] = ir\n",
      "        nbjdta[0,ir*lengthj:(ir+1)*lengthj] = range(startj,endj)\n",
      "        nbrdta[0,ir*lengthj:(ir+1)*lengthj] = ir\n",
      "        \n",
      "    for ib in range(0,lengthj*r):\n",
      "        sossheig[:,0,ib] = surges\n",
      "        time_counter[:] = tc+1\n",
      "        vobtcrtx[:,0,ib] = 0*np.ones(len(surges))\n",
      "        vobtcrty[:,0,ib] = 0*np.ones(len(surges))\n",
      "\n",
      "    ssh_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_website(save_path):\n",
      "    \"\"\"Reads a website with Neah Bay storm surge predictions/observations\n",
      "    The data is in a file in the given save_path\n",
      "    returns the filename where the surge data is stored\"\"\"\n",
      "    url='http://www.nws.noaa.gov/mdl/etsurge/index.php?page=stn&region=wc&datum=msl&list=&map=0-48&type=both&stn=waneah'\n",
      "    response = urllib2.urlopen(url)\n",
      "    html = response.read()\n",
      "\n",
      "    #use BeautifulSoup to parse out table\n",
      "    soup = BeautifulSoup(html)\n",
      "    table=str(soup.findAll('pre'))\n",
      "    table=table.replace('<pre>','')\n",
      "    table=table.replace('</pre>','')\n",
      "    table=table.replace('[','')\n",
      "    table=table.replace(']','')\n",
      "    \n",
      "    #save the table as a text file. Use the date the table was generated as a file name?\n",
      "    today=datetime.datetime.strftime(datetime.datetime.now(pytz.timezone('UTC')),'%Y-%m-%d')\n",
      "    filename = os.path.join(save_path,'txt','sshNB_{}.txt'.format(today))\n",
      "    text_file = open(filename, \"w\")\n",
      "    text_file.write(table)\n",
      "    text_file.close()\n",
      "    \n",
      "    return filename\n",
      "\n",
      "#this function will have to return the text file name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_surge_data(filename):\n",
      "    \"\"\"Loads the textfile with surge predictions\n",
      "    returns as a data structure\"\"\"\n",
      "\n",
      "    #Loading the data from that text file.\n",
      "    data = pd.read_csv(filename,skiprows=3,names=['date','surge','tide','obs','fcst','anom','comment'], \n",
      "    comment='#')\n",
      "    #drop rows with all Nans\n",
      "    data= data.dropna(how='all')    \n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that all the functions are defined, write out the procedure for saving the files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#define stuff we will need for saving netcdfs - JdF parameters.\n",
      "startj = 384\n",
      "endj = 471\n",
      "lengthj = endj-startj\n",
      "r = 1\n",
      "\n",
      "fB = nc.Dataset('/data/nsoontie/MEOPAR/NEMO-forcing/grid/bathy_meter_SalishSea2.nc','r')\n",
      "lat = fB.variables['nav_lat'][:]\n",
      "lon = fB.variables['nav_lon'][:]\n",
      "fB.close()\n",
      "\n",
      "YEAR=2014; #year of data. Need to change this when we hit 2015.\n",
      "SAVE_PATH = '/ocean/nsoontie/MEOPAR/sshNeahBay/'\n",
      "\n",
      "#load surge data\n",
      "textfile = read_website(SAVE_PATH)\n",
      "data = load_surge_data(textfile)\n",
      "\n",
      "#Process the dates to find days with a full prediction\n",
      "dates=np.array(data.date.values)\n",
      "for i in range(dates.shape[0]):\n",
      "    dates[i]=to_datetime(dates[i],YEAR)\n",
      "dates_list=list_full_days(dates)\n",
      "\n",
      "#loop through full days and save netcdf\n",
      "for d in dates_list:\n",
      "    surges,tc,forecast_flag=retrieve_surge(d,dates,data)\n",
      "    save_netcdf(d,tc,surges,forecast_flag,textfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "file format: NETCDF4\n",
        "Conventions: CF-1.6\n",
        "title: Neah Bay SSH hourly values\n",
        "institution: Dept of Earth, Ocean & Atmospheric Sciences, University of British Columbia\n",
        "source: REQUIRED\n",
        "references: REQUIRED\n",
        "history: [2014-11-04 09:03:41] Created netCDF4 zlib=True dataset.\n",
        "comment: Observation from Neah Bay storm surge website\n",
        "file format: NETCDF4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Conventions: CF-1.6\n",
        "title: Neah Bay SSH hourly values\n",
        "institution: Dept of Earth, Ocean & Atmospheric Sciences, University of British Columbia\n",
        "source: REQUIRED\n",
        "references: REQUIRED\n",
        "history: [2014-11-04 09:03:41] Created netCDF4 zlib=True dataset.\n",
        "comment: Prediction from Neah Bay storm surge website\n",
        "file format: NETCDF4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Conventions: CF-1.6\n",
        "title: Neah Bay SSH hourly values\n",
        "institution: Dept of Earth, Ocean & Atmospheric Sciences, University of British Columbia\n",
        "source: REQUIRED\n",
        "references: REQUIRED\n",
        "history: [2014-11-04 09:03:41] Created netCDF4 zlib=True dataset.\n",
        "comment: Prediction from Neah Bay storm surge website\n",
        "file format: NETCDF4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Conventions: CF-1.6\n",
        "title: Neah Bay SSH hourly values\n",
        "institution: Dept of Earth, Ocean & Atmospheric Sciences, University of British Columbia\n",
        "source: REQUIRED\n",
        "references: REQUIRED\n",
        "history: [2014-11-04 09:03:41] Created netCDF4 zlib=True dataset.\n",
        "comment: Prediction from Neah Bay storm surge website\n",
        "file format: NETCDF4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Conventions: CF-1.6\n",
        "title: Neah Bay SSH hourly values\n",
        "institution: Dept of Earth, Ocean & Atmospheric Sciences, University of British Columbia\n",
        "source: REQUIRED\n",
        "references: REQUIRED\n",
        "history: [2014-11-04 09:03:42] Created netCDF4 zlib=True dataset.\n",
        "comment: Prediction from Neah Bay storm surge website\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Next Steps: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Module?\n",
      "2. Automate?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}